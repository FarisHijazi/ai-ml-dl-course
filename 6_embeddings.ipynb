{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/farishijazi/ai-ml-dl-course/blob/master/6_embeddings.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll be using the [face_recognition](https://github.com/ageitgey/face_recognition) library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every ML model has a training phase and a test phase\n",
    "\n",
    "in the training phase, face recognition learns on multiple pictures of the same person and tries to make them close together, while making pictures of different people far apart\n",
    "\n",
    "![](https://gombru.github.io/assets/ranking_loss/pairwise_ranking_loss_faces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our prediction phase, we'll be comparing the embeddings (magic numbers) of different faces, because we can't compare the images directly\n",
    "\n",
    "![](https://miro.medium.com/v2/format:webp/0*T5X0551oS70qy8Jy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "if we cluster these embeddings, we can see that similar people have similar embeddings\n",
    "\n",
    "![](https://www.researchgate.net/publication/311066908/figure/fig2/AS:433599888531464@1480389677776/Clustering-of-track-faces-into-a-cloud-comprising-of-clusters-subclusters-and-outliers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22436\\3699439087.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_image_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"my_picture.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mface_locations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"cnn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "\n",
    "image = face_recognition.load_image_file(\"my_picture.jpg\")\n",
    "face_locations = face_recognition.face_locations(image, model=\"cnn\")\n",
    "\n",
    "# face_locations is now an array listing the co-ordinates of each face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "\n",
    "picture_of_me = face_recognition.load_image_file(\"me.jpg\")\n",
    "my_face_encoding = face_recognition.face_encodings(picture_of_me)[0]\n",
    "\n",
    "# my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!\n",
    "\n",
    "unknown_picture = face_recognition.load_image_file(\"unknown.jpg\")\n",
    "unknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]\n",
    "\n",
    "# Now we can see the two face encodings are of the same person with `compare_faces`!\n",
    "\n",
    "results = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)\n",
    "\n",
    "if results[0] == True:\n",
    "    print(\"It's a picture of me!\")\n",
    "else:\n",
    "    print(\"It's not a picture of me!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d31dcd7824a7bcdff63cf64e148b2e1d7185ee6870704eed91b67fbabe586800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
